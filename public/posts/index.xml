<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Jorge López</title>
    <link>/posts/</link>
    <description>Recent content in Posts on Jorge López</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 04 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Bootstrapped White&#39;s test for checking homoskedasticity in small samples</title>
      <link>/posts/bootstrapped-white-s-test-for-homoskedasticity-check-in-small-samples/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/bootstrapped-white-s-test-for-homoskedasticity-check-in-small-samples/</guid>
      <description>I came across this paper where the authors developed a bootstrapped version of the well-known White test. This test checks whether the variance of the residuals in a linear regression model is constant (homoskedasticity). Remember that this is one of the assumptions for a linear regression model to be valid.
The test statistic can be formulated as:
 \(W = nR^2\)  where \(n\) is the number of observations and \(R^2\) is the R-squared of the auxiliary regression of the residuals against fitted values (further details for example here).</description>
    </item>
    
    <item>
      <title>This is why you should consider using model-based clustering</title>
      <link>/posts/this-is-why-you-should-consider-using-model-based-clustering/</link>
      <pubDate>Wed, 29 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/this-is-why-you-should-consider-using-model-based-clustering/</guid>
      <description>Let’s suppose you have the following data. It contains 177 wines with some characteristics about them. You’d like to group them in such way you can create a marketing campaign, for example.
set.seed(143) pkgs &amp;lt;- c(&amp;quot;mclust&amp;quot;, &amp;quot;dplyr&amp;quot;) invisible(lapply(pkgs, require, character.only = TRUE)) df &amp;lt;- read.csv(&amp;#39;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&amp;#39;) names(df) &amp;lt;- c(&amp;#39;Type&amp;#39;, &amp;#39;Alcohol&amp;#39;, &amp;#39;Malic_acid&amp;#39;, &amp;#39;Ash&amp;#39;, &amp;#39;Alcalinity&amp;#39;, &amp;#39;Magnesium&amp;#39;, &amp;#39;Total_phenols&amp;#39;, &amp;#39;Flavanoids&amp;#39;, &amp;#39;Nonflavanoid_phenols&amp;#39;, &amp;#39;Proanthocyanins&amp;#39;, &amp;#39;Color_intensity&amp;#39;, &amp;#39;Hue&amp;#39;, &amp;#39;OD280&amp;#39;, &amp;#39;Proline&amp;#39;) df &amp;lt;- df %&amp;gt;% select(-Type) glimpse(df) ## Observations: 177 ## Variables: 13 ## $ Alcohol &amp;lt;dbl&amp;gt; 13.</description>
    </item>
    
    <item>
      <title>Maximum Likelihood Estimation and the Newton-Raphson method</title>
      <link>/posts/maximum-likelihood-estimation-and-the-newton-raphson-method/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/maximum-likelihood-estimation-and-the-newton-raphson-method/</guid>
      <description>The Maximum Likelihood Estimation (MLE) is probably one of the most well-known methods for estimating the parameters of a particular statistical model, given the data. It aims at finding the parameter values that makes the observed data most likely under the assumed statistical model.
Let \(X_1, ... X_n\) be independent and identically distributed random variables. We assume that the data are drawn from a distribution with density \(f(x|\theta)\). Given the data, we define the likelihood as follows:</description>
    </item>
    
    <item>
      <title>Entendiendo los métodos Markov Chain Monte Carlo</title>
      <link>/posts/entendiendo-los-metodos-de-cadenas-de-markov-monte-carlo/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/entendiendo-los-metodos-de-cadenas-de-markov-monte-carlo/</guid>
      <description>Una de las cosas más atractivas de la inferencia bayesiana es que permite la incorporación de conocimiento previo o creencias mediante distribuciones de probabilidad sobre los parámetros de interés. Por ejemplo, uno querría estimar cuál es la tasa de letalidad de una enfermedad y querría incorporar la información de un estudio previo, que indica que es del 0.5%. Esto confronta con la escuela frecuentista de la estadística, que asume que las probabilidades están estrictamente relacionadas con la frecuencia de los eventos.</description>
    </item>
    
    <item>
      <title>Building a simple football player rating model</title>
      <link>/posts/developing-a-simple-football-player-rating-model/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/developing-a-simple-football-player-rating-model/</guid>
      <description>This model is somehow inspired by the PlayeRank methodology developed by Pappalardo et al. (2019). You can see the work-in-progress code of the following analysis here.
 This post aims to show a simple two-step model for rating football players. To this end, I’ll take the FA Women’s Super League as an example. The data comes from the StatsBomb Open Data repository, which has all the details of the events they collect.</description>
    </item>
    
    <item>
      <title>Modelizando resultados de partidos de fútbol: Regresión de Poisson</title>
      <link>/posts/modelizando-resultados-de-partidos-de-f%C3%BAtbol-a-trav%C3%A9s-de-regresi%C3%B3n-de-poisson/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/modelizando-resultados-de-partidos-de-f%C3%BAtbol-a-trav%C3%A9s-de-regresi%C3%B3n-de-poisson/</guid>
      <description>Este post está plenamente inspirado en este artículo.
 En los últimos días he estado intentando leer información sobre aplicaciones de estadística y machine learning en el campo de los deportes, concretamente en el fútbol. De mis primeras impresiones del llamado soccer/football analytics, extraigo algunas conclusiones preliminares:
Hay mucho camino recorrido, pero queda por recorrer: es relativamente fácil encontrar todo tipo de papers y artículos relacionados con todos los subámbitos del análisis en el fútbol: predicción de resultados, rendimiento de jugadores, scouting, la familia xG y modelos de predicción de éstos, etc, aunque no he encontrado manuales/libros de referencia que cubran todo lo anterior en detalle.</description>
    </item>
    
    <item>
      <title>¿Qué dice hoy la prensa? Topic modeling con R</title>
      <link>/posts/que-dice-hoy-la-prensa-topic-modeling-con-r/</link>
      <pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/que-dice-hoy-la-prensa-topic-modeling-con-r/</guid>
      <description>En el último post estuve jugando un poco con tidytext y algunas otras herramientas que ofrece R en cuanto a text mining se refiere. Una de las cosas que quedó pendiente fue hacer algo de topic modeling, para lo cual escribo este post. De Wikipedia:
 In machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract “topics” that occur in a collection of documents.</description>
    </item>
    
    <item>
      <title>Análisis de texto con R: jugando un poco con tidytext</title>
      <link>/posts/analisis-de-texto-con-r-jugando-un-poco-con-tidytext/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/analisis-de-texto-con-r-jugando-un-poco-con-tidytext/</guid>
      <description>Hace unos meses me leí el libro de Text Mining with R de Julia Silge y David Robinson. En él, los autores introducen el término tidy text format para referirse a la adaptación de los principios del tidyverse a todo lo referido al análisis de texto. Si te interesa el tema, una lectura muy recomendable.
Una de las cosas que me interesaba comprobar es cuán fácil es replicar algunos análisis del libro con datos reales (los del libro también lo son, pero evidentemente los ejemplos son agradecidos) y también con texto en español.</description>
    </item>
    
    <item>
      <title>Making some stuff with gganimate</title>
      <link>/posts/making-some-stuff-with-gganimate/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/making-some-stuff-with-gganimate/</guid>
      <description>I wanted to make some stuff with the gganimate package since I was aware of the existence of the new API. Yesterday I found the data I was seeking in order to move forward!
El País and its team are making an effort to collect data from many different pollsters and also calibrate some statistical models. The methodology is also explained in the previous link.
My goal here was just focused on trying gganimate, so here is the reproducible example (and the result):</description>
    </item>
    
    <item>
      <title>Getting public holidays by country</title>
      <link>/posts/getting-public-holidays-by-country/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/getting-public-holidays-by-country/</guid>
      <description>I’ve been recently working on a time series model to which I wanted to include the public holidays of Spain and Portugal. After trying different approaches I decided to move forward with prophet which, by the way, I strongly recommend it.
But this post comes to my mind because I’d like to tell some options we have to get the public holidays by country. I don’t want to go into details about the specificities of what a public holidays mean (regional or local ones are excluded in this analysis, for example).</description>
    </item>
    
    <item>
      <title>Making my own website with blogdown</title>
      <link>/posts/2019-02-01-blogdown/</link>
      <pubDate>Mon, 04 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019-02-01-blogdown/</guid>
      <description>The first thing I’d recommend to anyone who wants to build a website from R using blogdown is to read the book of the author of this package, Yihui Xie.
Therefore, this post isn’t intended to be a guide on how to make your own website but a way to tell my experience through the process. The details of what each folder should contain within the project are fully and very well explained on the book linked above.</description>
    </item>
    
    <item>
      <title>Encuentro de usuarios R en Canarias</title>
      <link>/posts/2019-01-31-encuentro-usuarios-r/</link>
      <pubDate>Thu, 31 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019-01-31-encuentro-usuarios-r/</guid>
      <description>Nada me complace más que iniciar esta nueva web y blog anunciando que el próximo 25 de marzo se llevará a cabo la primera reunión de usuarios de R –#rstats– en Canarias.
El encuentro se realizará en la Sociedad de Promoción Económica de Gran Canaria durante todo el día y estará organizado por el también reciente grupo de usuarios de R en Canarias.
La inscripción y propuesta de charlas (!</description>
    </item>
    
  </channel>
</rss>